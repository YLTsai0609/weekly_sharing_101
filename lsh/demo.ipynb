{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e97111f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "from typing import Tuple, Set, List, Union\n",
    "from scipy.sparse import linalg as spl\n",
    "from numpy import linalg as LA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42f5b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "\n",
    "N = 1000\n",
    "D= 50\n",
    "\n",
    "A = np.random.randn(N,D)\n",
    "# artificially make some similar to others\n",
    "A[5] = A[99] +np.random.randn(D)*0.05\n",
    "A[20] = A[85] +np.random.randn(D)*0.15\n",
    "A[13] = A[19] +np.random.randn(D)*0.25\n",
    "A[56] = A[71] +np.random.randn(D)*0.5\n",
    "A[45] = A[49] +np.random.randn(D)*0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "967e08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(u,v):\n",
    "    norm = np.linalg.norm(u)*np.linalg.norm(v)\n",
    "    cosine = u@v/norm\n",
    "    ang = np.arccos(cosine)\n",
    "    return 1-ang/np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe1d60a",
   "metadata": {},
   "source": [
    "# Brute-force\n",
    "\n",
    "$N$ docs\n",
    "\n",
    "Time Complexity : $O(N^2)$\n",
    "\n",
    "Space Complexity : $O(1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45d0a63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute force calculation time: 4.750\n",
      "Discovered pairs:\n",
      "Pair: (5, 99),\tSimilarity: 0.99.\n",
      "Pair: (13, 19),\tSimilarity: 0.92.\n",
      "Pair: (20, 85),\tSimilarity: 0.95.\n",
      "Pair: (56, 71),\tSimilarity: 0.86.\n"
     ]
    }
   ],
   "source": [
    "true_pairs_dict = {}\n",
    "\n",
    "thresh = 0.8\n",
    "\n",
    "start = time.time()\n",
    "for (i,u),(j,v) in itertools.combinations([(i,x) for i,x in enumerate(A)],2):\n",
    "    val = cossim(u,v)\n",
    "    if val > thresh:\n",
    "        true_pairs_dict[(i,j)] = val\n",
    "t_brute = time.time()-start\n",
    "\n",
    "# save just the keys without the values. Easier to compare later to LSH\n",
    "true_pairs = set(true_pairs_dict.keys())\n",
    "\n",
    "print(f\"Brute force calculation time: {t_brute:.3f}\")\n",
    "print(f\"Discovered pairs:\")\n",
    "for k, v in true_pairs_dict.items():\n",
    "    print(f\"Pair: {k},\\tSimilarity: {v:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd04fc",
   "metadata": {},
   "source": [
    "# LSH\n",
    "\n",
    "\n",
    "$N$ docs,\n",
    "$D$ features,\n",
    "$K$ hashes buckets, \n",
    "\n",
    "Time Complexity : $O(N^2)$\n",
    "\n",
    "Space Complexity :\n",
    "\n",
    "(depends on your implementation)\n",
    "\n",
    "1. hash function : $O(DK)$\n",
    "2. hashed values : $O(K)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9be0c223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition probability: 0.80\n"
     ]
    }
   ],
   "source": [
    "b, r = 50, 18\n",
    "\n",
    "n = b*r\n",
    "print(f\"Transition probability: {(1/b)**(1/r):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e830e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomProjectionLSH():\n",
    "    \n",
    "    def __init__(self,\n",
    "                n_signature : int,\n",
    "                n_input_dimension : int,\n",
    "                b : int,\n",
    "                r : int,\n",
    "                threshold = float,\n",
    "                seed = int):\n",
    "        \"\"\"\n",
    "        Consturct Random Projection LSH to find the candidate pair\n",
    "        \n",
    "        \"\"\"\n",
    "        assert n_signature == b * r, 'signatures should be bands (b) * rows per band (r)'\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        self.n_input_dimension = n_input_dimension\n",
    "        self.n_signature = n_signature\n",
    "        self.threshold = threshold\n",
    "        self.b = b\n",
    "        self.r = r\n",
    "        # create a gaussion distributed matrix\n",
    "        self.hyperplanes = np.random.randn(n_input_dimension, n_signature)\n",
    "        self.signature = None\n",
    "        self.n_observation = None\n",
    "    \n",
    "    def fit(self, input_matrix : np.ndarray):\n",
    "        \"\"\"\n",
    "        input_matrix (np.ndarray) - (n_observations, n_input_dimension)\n",
    "        \n",
    "        Hint:\n",
    "        \n",
    "        Use input_matrix.dot(self.hyperplane) instead of \n",
    "        np.dot(input_matrix, self.hyperplane) due to some implementation details\n",
    "        https://stackoverflow.com/questions/33817189/why-is-vector-dot-product-slower-with-scipys-sparse-csr-matrix-than-numpys-den\n",
    "        \n",
    "        \"\"\"\n",
    "        self.n_observation = input_matrix.shape[0]\n",
    "        self.input_matrix = input_matrix\n",
    "        # build signature , shape (n_observation, n_signature)\n",
    "        self.signature = input_matrix.dot(self.hyperplanes)\n",
    "        self.signature = self.signature >= 0\n",
    "        self.signature = np.reshape(self.signature,\n",
    "                                    (self.n_observation, self.b, self.r))\n",
    "        self.hashed_values = self._generate_hash()\n",
    "        \n",
    "    def find_candidates(self, dtype='dense') -> Tuple[Set, int]:\n",
    "        \"\"\"\n",
    "        Apply OR logic\n",
    "        \n",
    "        In each band\n",
    "        check is there other observation in the same bucket\n",
    "        if yes, there is a cindidate\n",
    "            output : \n",
    "            \n",
    "            duplicates : candidate pair by id\n",
    "            n_candidates : for all ids, number of candidates\n",
    "        \"\"\"\n",
    "        if dtype == 'dense':\n",
    "            cos_sim = self._consine_similarity_dense\n",
    "        elif dtype == 'sparse':\n",
    "            cos_sim = self._cosine_similarity_sparse\n",
    "        \n",
    "        ##### Apply OR Logic\n",
    "        candidates = []\n",
    "        for i in range(self.b):\n",
    "            un_values, counts = np.unique(self.hashed_values[:, i],\n",
    "                                          return_counts=True) # get unique integers and their count\n",
    "            \n",
    "            non_unique_values = un_values[counts > 1] # identify integers which appear more than once\n",
    "            \n",
    "            ####### Might be at least 1\n",
    "            for val in non_unique_values: # store duplicate integers as candidates\n",
    "                candidates.append(np.where(\n",
    "                    self.hashed_values[:, i] == val)[0])\n",
    "        \n",
    "        n_candidates = len(candidates)\n",
    "\n",
    "        # get cosine distance for every candidate\n",
    "        dist = [cos_sim(self.input_matrix, cand[0], cand[1])\n",
    "                for cand \n",
    "                in candidates] # get the distance for all candidates\n",
    "\n",
    "        # get duplicates\n",
    "        duplicates = set(\n",
    "            (candidates[i][0], candidates[i][1], dist[i])\n",
    "            for i in range(len(dist)) \n",
    "            if dist[i] >= self.threshold) \n",
    "\n",
    "        return duplicates, n_candidates\n",
    "    \n",
    "    def _consine_similarity_dense(self, X, i, j) -> float:\n",
    "        \n",
    "        return np.dot(X[i], X[j]) / (LA.norm(X[i]) * LA.norm(X[j]))\n",
    "    \n",
    "    def _cosine_similarity_sparse(self, X, i, j) -> float:\n",
    "        \"\"\"\n",
    "        This function is for sparse vector calculations\n",
    "        \"\"\"\n",
    "        \n",
    "        i_norm = spl.norm(X[i])\n",
    "        j_norm = spl.norm(X[j])\n",
    "        ij_dot = X[i].dot(X[j].T)[0, 0]\n",
    "\n",
    "        return ij_dot/(i_norm*j_norm)\n",
    "    \n",
    "    def _generate_hash(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply and logic for rows per band\n",
    "        \n",
    "        Hash all of element in \n",
    "        the signature matrix(n_observations, b, r)\n",
    "        into bucket by element-wise multify between\n",
    "        \n",
    "        signature and bucket_id\n",
    "        \n",
    "        output : \n",
    "            signature_matrix (band) shape : (n_oberservation, b)\n",
    "        \"\"\"\n",
    "        # AND hashing\n",
    "        vals = 2**np.repeat(\n",
    "            [np.repeat([np.arange(self.r)], self.b, axis=0)],\n",
    "            self.n_observation,\n",
    "            axis=0)\n",
    "        \n",
    "        # elementwise product\n",
    "        # construct hashed bucket\n",
    "        hashed_values = np.multiply(self.signature, vals)\n",
    "        hashed_values = np.sum(hashed_values, axis=2)\n",
    "        return hashed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa7f898b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair :(5 99), Similarity: 0.9990037491636654\n",
      "Pair :(13 19), Similarity: 0.968380463048351\n",
      "Pair :(20 85), Similarity: 0.9892354755140065\n",
      "Pair :(56 71), Similarity: 0.900335887084203\n",
      "\n",
      "LSH calculation time: 0.032\n",
      "speed up 148.3x\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "rplsh = RandomProjectionLSH(\n",
    "    n_signature=900,\n",
    "    n_input_dimension=50,\n",
    "    b=50,\n",
    "    r=18,\n",
    "    threshold = 0.75,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "rplsh.fit(A)\n",
    "\n",
    "lsh_similar, n_lsh_similar = rplsh.find_candidates()\n",
    "\n",
    "t_lsh = time.time() - start\n",
    "\n",
    "for pair in lsh_similar:\n",
    "    _from, _to, sim = pair\n",
    "    print(f'Pair :({_from} {_to}), Similarity: {sim}')\n",
    "\n",
    "print()\n",
    "print(f\"LSH calculation time: {t_lsh:.3f}\")\n",
    "print(f'speed up {(t_brute / t_lsh):.1f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b785606b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 50)\n",
      "[[175831 174638  66712 ...  11154 252485 125380]\n",
      " [127321     14 172531 ...  67608  38625 133278]\n",
      " [153253 260714 251782 ...  80584 242572 222939]\n",
      " ...\n",
      " [159265 151458  95319 ... 105137  66207 260123]\n",
      " [137051 256712 179063 ... 196550 126953 213781]\n",
      " [ 47401 183253  85981 ...  24836  63846 104611]]\n"
     ]
    }
   ],
   "source": [
    "# hashes\n",
    "\n",
    "print(rplsh.hashed_values.shape)\n",
    "print(rplsh.hashed_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5444961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d912f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
